{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling All Autobots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import exposure\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for histogram matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for histogram matching\n",
    "def histogram_matching(source, template):\n",
    "    matched = exposure.match_histograms(source, template, channel_axis=None)\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data training\n",
    "image1 = 'Images/training/drishtiGS_017.png'\n",
    "image2 = 'Images/training/drishtiGS_032.png'\n",
    "image3 = 'Images/training/drishtiGS_036.png'\n",
    "image4 = 'Images/training/drishtiGS_037.png'\n",
    "image5 ='Images/training/drishtiGS_040.png'\n",
    "image6 = 'Images/training/drishtiGS_042.png'\n",
    "image7 = 'Images/training/drishtiGS_049.png'\n",
    "image8 = 'Images/training/drishtiGS_057.png'\n",
    "image9 = 'Images/training/drishtiGS_060.png'\n",
    "image10 = 'Images/training/drishtiGS_063.png'\n",
    "image11 = 'Images/training/drishtiGS_064.png'\n",
    "image12 = 'Images/training/drishtiGS_066.png'\n",
    "image13 = 'Images/training/drishtiGS_068.png'\n",
    "image14 = 'Images/training/drishtiGS_069.png'\n",
    "image15 = 'Images/training/drishtiGS_080.png'\n",
    "image16 = 'Images/training/drishtiGS_081.png'\n",
    "image17 = 'Images/training/drishtiGS_084.png'\n",
    "image18 = 'Images/training/drishtiGS_088.png'\n",
    "image19 = 'Images/training/drishtiGS_094.png'\n",
    "image20 = 'Images/training/drishtiGS_098.png'\n",
    "\n",
    "#Data Testing\n",
    "image21 = 'Images/testing/drishtiGS_033.png'\n",
    "image22 = 'Images/testing/drishtiGS_038.png'\n",
    "image23 = 'Images/testing/drishtiGS_041.png'\n",
    "image24 = 'Images/testing/drishtiGS_046.png'\n",
    "image25 = 'Images/testing/drishtiGS_051.png'\n",
    "image26 = 'Images/testing/drishtiGS_058.png'\n",
    "image27 = 'Images/testing/drishtiGS_076.png'\n",
    "image28 = 'Images/testing/drishtiGS_089.png'\n",
    "image29 = 'Images/testing/drishtiGS_090.png'\n",
    "image30 = 'Images/testing/drishtiGS_092.png'\n",
    "\n",
    "\n",
    "# Buat list yang berisi semua variabel gambar\n",
    "images = [\n",
    "    image1, image2, image3, image4, image5,\n",
    "    image6, image7, image8, image9, image10,\n",
    "    image11, image12, image13, image14, image15,\n",
    "    #image16, \n",
    "    image17, #image18, \n",
    "    image19, image20,\n",
    "    image21, image22, image23, image24, image25,\n",
    "    image26, image27, image28, image29, image30\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data OC Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "oc1 = 'Images/OC_training/drishtiGS_017_CupAvgBoundary_OC_img.png'\n",
    "oc2 = 'Images/OC_training/drishtiGS_032_CupAvgBoundary_OC_img.png'\n",
    "oc3 = 'Images/OC_training/drishtiGS_036_CupAvgBoundary_OC_img.png'\n",
    "oc4 = 'Images/OC_training/drishtiGS_037_CupAvgBoundary_OC_img.png'\n",
    "oc5 = 'Images/OC_training/drishtiGS_040_CupAvgBoundary_OC_img.png'\n",
    "oc6 = 'Images/OC_training/drishtiGS_042_CupAvgBoundary_OC_img.png'\n",
    "oc7 = 'Images/OC_training/drishtiGS_049_CupAvgBoundary_OC_img.png'\n",
    "oc8 = 'Images/OC_training/drishtiGS_057_CupAvgBoundary_OC_img.png'\n",
    "oc9 = 'Images/OC_training/drishtiGS_060_CupAvgBoundary_OC_img.png'\n",
    "oc10 = 'Images/OC_training/drishtiGS_063_CupAvgBoundary_OC_img.png'\n",
    "oc11 = 'Images/OC_training/drishtiGS_064_CupAvgBoundary_OC_img.png'\n",
    "oc12 = 'Images/OC_training/drishtiGS_066_CupAvgBoundary_OC_img.png'\n",
    "oc13 = 'Images/OC_training/drishtiGS_068_CupAvgBoundary_OC_img.png'\n",
    "oc14 = 'Images/OC_training/drishtiGS_069_CupAvgBoundary_OC_img.png'\n",
    "oc15 = 'Images/OC_training/drishtiGS_080_CupAvgBoundary_OC_img.png'\n",
    "oc16 = 'Images/OC_training/drishtiGS_080_CupAvgBoundary_OC_img.png'\n",
    "oc17 = 'Images/OC_training/drishtiGS_081_CupAvgBoundary_OC_img.png'\n",
    "oc18 = 'Images/OC_training/drishtiGS_084_CupAvgBoundary_OC_img.png'\n",
    "oc19 = 'Images/OC_training/drishtiGS_094_CupAvgBoundary_OC_img.png'\n",
    "oc20 = 'Images/OC_training/drishtiGS_098_CupAvgBoundary_OC_img.png'\n",
    "\n",
    "oc21 = 'Images/OC_testing/drishtiGS_033_CupAvgBoundary_OC_img.png'\n",
    "oc22 = 'Images/OC_testing/drishtiGS_038_CupAvgBoundary_OC_img.png'\n",
    "oc23 = 'Images/OC_testing/drishtiGS_041_CupAvgBoundary_OC_img.png'\n",
    "oc24 = 'Images/OC_testing/drishtiGS_046_CupAvgBoundary_OC_img.png'\n",
    "oc25 = 'Images/OC_testing/drishtiGS_051_CupAvgBoundary_OC_img.png'\n",
    "oc26 = 'Images/OC_testing/drishtiGS_058_CupAvgBoundary_OC_img.png'\n",
    "oc27 = 'Images/OC_testing/drishtiGS_076_CupAvgBoundary_OC_img.png'\n",
    "oc28 = 'Images/OC_testing/drishtiGS_089_CupAvgBoundary_OC_img.png'\n",
    "oc29 = 'Images/OC_testing/drishtiGS_090_CupAvgBoundary_OC_img.png'\n",
    "oc30 = 'Images/OC_testing/drishtiGS_092_CupAvgBoundary_OC_img.png'\n",
    "\n",
    "# Buat list yang berisi semua variabel gambar\n",
    "ocs = [\n",
    "    oc1, oc2, oc3, oc4, oc5,\n",
    "    oc6, oc7, oc8, oc9, oc10,\n",
    "    oc11, oc12, oc13, oc14, oc15,\n",
    "    #oc16, \n",
    "    oc17, #oc18, \n",
    "    oc19, oc20,\n",
    "    oc21, oc22, oc23, oc24, oc25,\n",
    "    oc26, oc27, oc28, oc29, oc30\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OD Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data training\n",
    "actual1 = 'Images/OD_training/drishtiGS_017_ODAvgBoundary_OD_img.png'\n",
    "actual2 = 'Images/OD_training/drishtiGS_032_ODAvgBoundary_OD_img.png'\n",
    "actual3 = 'Images/OD_training/drishtiGS_036_ODAvgBoundary_OD_img.png'\n",
    "actual4 = 'Images/OD_training/drishtiGS_037_ODAvgBoundary_OD_img.png'\n",
    "actual5 ='Images/OD_training/drishtiGS_040_ODAvgBoundary_OD_img.png'\n",
    "actual6 = 'Images/OD_training/drishtiGS_042_ODAvgBoundary_OD_img.png'\n",
    "actual7 = 'Images/OD_training/drishtiGS_049_ODAvgBoundary_OD_img.png'\n",
    "actual8 = 'Images/OD_training/drishtiGS_057_ODAvgBoundary_OD_img.png'\n",
    "actual9 = 'Images/OD_training/drishtiGS_060_ODAvgBoundary_OD_img.png'\n",
    "actual10 = 'Images/OD_training/drishtiGS_063_ODAvgBoundary_OD_img.png'\n",
    "actual11 = 'Images/OD_training/drishtiGS_064_ODAvgBoundary_OD_img.png'\n",
    "actual12 = 'Images/OD_training/drishtiGS_066_ODAvgBoundary_OD_img.png'\n",
    "actual13 = 'Images/OD_training/drishtiGS_068_ODAvgBoundary_OD_img.png'\n",
    "actual14 = 'Images/OD_training/drishtiGS_069_ODAvgBoundary_OD_img.png'\n",
    "actual15 = 'Images/OD_training/drishtiGS_080_ODAvgBoundary_OD_img.png'\n",
    "actual16 = 'Images/OD_training/drishtiGS_081_ODAvgBoundary_OD_img.png'\n",
    "actual17 = 'Images/OD_training/drishtiGS_084_ODAvgBoundary_OD_img.png'\n",
    "actual18 = 'Images/OD_training/drishtiGS_088_ODAvgBoundary_OD_img.png'\n",
    "actual19 = 'Images/OD_training/drishtiGS_094_ODAvgBoundary_OD_img.png'\n",
    "actual20 = 'Images/OD_training/drishtiGS_098_ODAvgBoundary_OD_img.png'\n",
    "\n",
    "#Data Testing\n",
    "actual21 = 'Images/OD_testing/drishtiGS_033_ODAvgBoundary_OD_img.png'\n",
    "actual22 = 'Images/OD_testing/drishtiGS_038_ODAvgBoundary_OD_img.png'\n",
    "actual23 = 'Images/OD_testing/drishtiGS_041_ODAvgBoundary_OD_img.png'\n",
    "actual24 = 'Images/OD_testing/drishtiGS_046_ODAvgBoundary_OD_img.png'\n",
    "actual25 = 'Images/OD_testing/drishtiGS_051_ODAvgBoundary_OD_img.png'\n",
    "actual26 = 'Images/OD_testing/drishtiGS_058_ODAvgBoundary_OD_img.png'\n",
    "actual27 = 'Images/OD_testing/drishtiGS_076_ODAvgBoundary_OD_img.png'\n",
    "actual28 = 'Images/OD_testing/drishtiGS_089_ODAvgBoundary_OD_img.png'\n",
    "actual29 = 'Images/OD_testing/drishtiGS_090_ODAvgBoundary_OD_img.png'\n",
    "actual30 = 'Images/OD_testing/drishtiGS_092_ODAvgBoundary_OD_img.png'\n",
    "\n",
    "# Buat list yang berisi semua variabel gambar\n",
    "actuals = [\n",
    "    actual1, actual2, actual3, actual4, actual5,\n",
    "    actual6, actual7, actual8, actual9, actual10,\n",
    "    actual11, actual12, actual13, actual14, actual15,\n",
    "    #actual16,\n",
    "     actual17, #actual18, \n",
    "     actual19, actual20,\n",
    "    actual21, actual22, actual23, actual24, actual25,\n",
    "    actual26, actual27, actual28, actual29, actual30\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read reference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reference image and input image\n",
    "reference_image_path = 'Images/training/drishtiGS_037.png'\n",
    "# Load the images\n",
    "reference_image = cv2.imread(reference_image_path)\n",
    "# Convert images to grayscale\n",
    "gray_reference = cv2.cvtColor(reference_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List untuk menyimpan %OD, F-Score, ROI Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_percents = []\n",
    "f_scores_od = []\n",
    "f_scores_oc = []\n",
    "roi_effs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterasi 20 Gambar untuk dapat ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa = 100\n",
    "xb = 100\n",
    "ya = 550\n",
    "yb = 1300\n",
    "counter = 1\n",
    "for image, actual, oc in zip(images, actuals, ocs):\n",
    "    fundus_image = cv2.imread(image)\n",
    "    fundus_image_copy = fundus_image.copy()\n",
    "    actual_od = cv2.imread(actual)\n",
    "    actual_oc = cv2.imread(oc)\n",
    "    actual_oc_gray = cv2.cvtColor(actual_oc, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_image = cv2.cvtColor(fundus_image, cv2.COLOR_BGR2GRAY)\n",
    "    # Perform histogram matching\n",
    "    matched_image = histogram_matching(gray_image, gray_reference)\n",
    "    # Get the dimensions of the image\n",
    "    height, width, _ = fundus_image.shape\n",
    "\n",
    "    # Crop the image along the y-axis from 550 to 1300\n",
    "    # Taking the entire width for x-axis\n",
    "    fundus_cropped = matched_image[ya:yb, xa:width-xb] #gray\n",
    "    RGB_cropped = fundus_image[ya:yb, xa:width-xb]\n",
    "\n",
    "    # Apply thresholding\n",
    "    _, binary_image = cv2.threshold(fundus_cropped, 100, 255, cv2.THRESH_BINARY)\n",
    "    # Perform morphological opening\n",
    "    kernel_open = np.ones((20, 20), np.uint8)\n",
    "    opened_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel_open)\n",
    "    # Perform morphological closing\n",
    "    kernel_close = np.ones((100, 100), np.uint8)\n",
    "    closed_image = cv2.morphologyEx(opened_image, cv2.MORPH_CLOSE, kernel_close)\n",
    "    \n",
    "    # Convert closed_image to grayscale if it's not already in grayscale\n",
    "    if len(closed_image.shape) > 2:\n",
    "        closed_image_gray = cv2.cvtColor(closed_image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        closed_image_gray = closed_image\n",
    "\n",
    "    # Ensure the image is in the correct format (CV_8UC1)\n",
    "    closed_image_uint8 = np.uint8(closed_image_gray)\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(closed_image_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Check if any contours were found\n",
    "    if not contours:\n",
    "        raise ValueError(\"No contours found in the image\")\n",
    "\n",
    "    # Get the largest contour\n",
    "    largest_contour_ROI = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    #Inisiasi x1,x2,y1,y2 agar menjadi global variabel\n",
    "    x1=0\n",
    "    x2=0\n",
    "    y1=0\n",
    "    y2=0\n",
    "\n",
    "    # Fit ellipse ke kontur terbesar\n",
    "    if len(largest_contour_ROI) >= 5:  # Minimum number of points required to fit ellipse\n",
    "        ellipse_ROI = cv2.fitEllipse(largest_contour_ROI)\n",
    "        \n",
    "        # Get the parameters of the ellipse\n",
    "        (center, axes, angle) = ellipse_ROI\n",
    "        center_x, center_y = center\n",
    "        width, height = axes\n",
    "\n",
    "        # Calculate bounding box of the ellipse\n",
    "        x1 = int(center_x - width // 2)-100\n",
    "        x2 = int(center_x + width // 2)+100\n",
    "        y1 = int(center_y - height // 2)-100\n",
    "        y2 = int(center_y + height // 2)+100\n",
    "\n",
    "        # Ensure the crop area is within the image bounds\n",
    "        y1, y2 = max(0, y1), min(fundus_cropped.shape[0], y2)\n",
    "        x1, x2 = max(0, x1), min(fundus_cropped.shape[1], x2)\n",
    "\n",
    "        # Crop the image to the bounding box of the ellipse\n",
    "        roi_cropped = fundus_cropped[y1:y2, x1:x2]\n",
    "        roi_rgb = RGB_cropped[y1:y2, x1:x2]\n",
    "\n",
    "        # Convert RGB_cropped to RGB format\n",
    "        color_image = cv2.cvtColor(RGB_cropped, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Draw ellipse on the color image\n",
    "        cv2.ellipse(color_image, ellipse_ROI, (0, 0, 255), 2)\n",
    "\n",
    "    else:\n",
    "        print(\"Kontur tidak cukup poin untuk fitting ellips.\")\n",
    "    \n",
    "    # Convert actual_od to a single-channel image if necessary\n",
    "    actual_od_gray = cv2.cvtColor(actual_od, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the number of non-zero pixels full images\n",
    "    od_pixel = cv2.countNonZero(actual_od_gray)\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    height, width, _ = actual_od.shape\n",
    "\n",
    "    # Crop the image along the y-axis from 700 to 1400\n",
    "    # Taking the entire width for x-axis\n",
    "    actual_od_crop = actual_od_gray[ya:yb, xa:width-xb]\n",
    "\n",
    "    # Cropping sesuai ROI\n",
    "    actual_od_roi = actual_od_crop[y1:y2, x1:x2]\n",
    "\n",
    "    # Calculate the total number of pixels in the ROI\n",
    "    total_pixel_roi = cv2.countNonZero(actual_od_roi)\n",
    "\n",
    "    # Calculate the percentage of ROI obtained in the image\n",
    "    od_percent = (total_pixel_roi/od_pixel) * 100\n",
    "    od_percents.append(od_percent)\n",
    "\n",
    "    # Get the shape of actual_od_roi\n",
    "    height_roi, width_roi = actual_od_roi.shape\n",
    "    \n",
    "    # Calculate the ROI Efficiency\n",
    "    roi_eff = total_pixel_roi*100 / (height_roi * width_roi)\n",
    "    roi_effs.append(roi_eff)\n",
    "\n",
    "    # Pisahkan gambar menjadi tiga komponen warna\n",
    "    B, G, R = cv2.split(roi_rgb)\n",
    "    \n",
    "    # Fungsi untuk menampilkan gambar menggunakan matplotlib\n",
    "    def show_image(title, img):\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "\n",
    "    # Konversi B, G, R dari format OpenCV (BGR) ke format yang bisa ditampilkan matplotlib (RGB)\n",
    "    # Untuk itu, kita perlu mengatur R, G, B ke channel-nya masing-masing di gambar RGB.\n",
    "    zeros = np.zeros_like(B)  # array dengan nilai nol untuk channel lain\n",
    "    R_img = cv2.merge([zeros, zeros, R])  # Hanya komponen merah\n",
    "    G_img = cv2.merge([zeros, G, zeros])  # Hanya komponen hijau\n",
    "    B_img = cv2.merge([B, zeros, zeros])  # Hanya komponen biru\n",
    "\n",
    "    # Calculate the histogram for each channel (B, G, R)\n",
    "    hist_b = cv2.calcHist([roi_rgb], [0], None, [256], [0, 256])\n",
    "    hist_g = cv2.calcHist([roi_rgb], [1], None, [256], [0, 256])\n",
    "    hist_r = cv2.calcHist([roi_rgb], [2], None, [256], [0, 256])\n",
    "\n",
    "    # Hitung nilai minimum dan maksimum dari setiap saluran warna\n",
    "    min_r, max_r = np.min(R), np.max(R)\n",
    "\n",
    "    # Lakukan kontras stretching pada saluran merah\n",
    "    r_stretched = ((R - min_r) / (max_r - min_r)) * 255\n",
    "    r_stretched = np.uint8(r_stretched)\n",
    "\n",
    "    # Gabungkan kembali saluran warna merah yang telah dimodifikasi dengan saluran hijau dan biru yang kosong\n",
    "    stretched_img = cv2.merge((zeros, zeros, r_stretched))\n",
    "\n",
    "    # Stretched hist\n",
    "    hist_stretch = cv2.calcHist([r_stretched], [0], None, [256], [0, 256])\n",
    "    \n",
    "    # Pisahkan citra menjadi tiga kanal: B, G, R\n",
    "    b, g, r = cv2.split(stretched_img)\n",
    "\n",
    "    # Buat mask berdasarkan kondisi threshold pada kanal merah\n",
    "    mask = r < 150\n",
    "\n",
    "    # Set nilai pada mask menjadi 0 pada kanal merah\n",
    "    r[mask] = 0\n",
    "\n",
    "    # Gabungkan kembali kanal B, G, R menjadi citra RGB\n",
    "    pass_if_img = cv2.merge([b, g, r])\n",
    "    pass_if_img_r = cv2.calcHist([pass_if_img], [2], None, [256], [0, 256])\n",
    "\n",
    "    # Perform morphological closing\n",
    "    kernel_close = np.ones((30,30),np.uint8)\n",
    "    closed_image = cv2.morphologyEx(pass_if_img, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "    # Convert closed_image to grayscale if it's not already in grayscale\n",
    "    if len(closed_image.shape) > 2:\n",
    "        closed_image_gray = cv2.cvtColor(closed_image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        closed_image_gray = closed_image\n",
    "\n",
    "    # Ensure the image is in the correct format (CV_8UC1)\n",
    "    closed_image_uint8 = np.uint8(closed_image_gray)\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(closed_image_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Check if any contours were found\n",
    "    if not contours:\n",
    "        raise ValueError(\"No contours found in the image\")\n",
    "\n",
    "    # Get the largest contour\n",
    "    largest_contour_OD = max(contours, key=cv2.contourArea)\n",
    "\n",
    "\n",
    "\n",
    "    # Fit ellipse ke kontur terbesar\n",
    "    if len(largest_contour_OD) >= 20:  # Minimum number of points required to fit ellipse\n",
    "        ellipse_OD = cv2.fitEllipse(largest_contour_OD)\n",
    "        # Ekstrak informasi pusat dan parameter ellips lainnya\n",
    "        (x_center, y_center), (major_axis, minor_axis), angle = ellipse_OD\n",
    "\n",
    "        # Hitung pusat baru dengan penambahan nilai translasi\n",
    "        new_x_center = x_center + x1 + 100 # ditambah sesuai cropping paling awal\n",
    "        new_y_center = y_center + y1 + 550 # ditambah sesuai cropping paling awal\n",
    "\n",
    "        # Bentuk ellips baru dengan pusat yang telah digeser\n",
    "        shifted_ellipse = ((new_x_center, new_y_center), (major_axis, minor_axis), angle)\n",
    "\n",
    "        # Gambar ellips yang diperkirakan di atas citra RGB\n",
    "        optic_disc_with_ellipse = cv2.ellipse(fundus_image, shifted_ellipse, (0, 255, 0), 2)     \n",
    "        optic_disc_filled = cv2.ellipse(fundus_image, shifted_ellipse, (255, 255, 255), -1)\n",
    "        optic_disc_filled_gray =cv2.cvtColor(optic_disc_filled, cv2.COLOR_BGR2GRAY)\n",
    "        _, optic_disc_filled_binary = cv2.threshold(optic_disc_filled_gray, 254, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        #Gambar bounding box\n",
    "        cv2.rectangle(fundus_image, (x1+xa, y1+ya), (x2+xa, y2+ya), (0, 255, 0), 2)\n",
    "        \n",
    "        # Menginisialisasi hitung untuk false negative, false positive, dan true positive\n",
    "        false_negative = 0\n",
    "        false_positive = 0\n",
    "        true_positive = 0\n",
    "\n",
    "        output_image_od = cv2.cvtColor(optic_disc_filled_binary, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Looping untuk setiap piksel di kedua citra perhitungan F-Score\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                # Mengecek false negative\n",
    "                if optic_disc_filled_binary[y, x] == 0 and actual_od_gray[y, x] == 255:\n",
    "                    false_negative += 1\n",
    "                    output_image_od[y, x] = [0, 0, 255]  # Merah\n",
    "                # Mengecek false positive\n",
    "                elif optic_disc_filled_binary[y, x] == 255 and actual_od_gray[y, x] == 0:\n",
    "                    false_positive += 1\n",
    "                    output_image_od[y, x] = [0, 255, 255]  # Kuning\n",
    "                # Mengecek true positive\n",
    "                elif optic_disc_filled_binary[y, x] == 255 and actual_od_gray[y, x] == 255:\n",
    "                    true_positive += 1\n",
    "                    output_image_od[y, x] = [0, 255, 0]  # Hijau\n",
    "        f_score_od = true_positive*100/(true_positive+false_positive+false_negative)\n",
    "        f_scores_od.append(f_score_od)\n",
    "\n",
    "        # Nama folder tempat gambar akan disimpan\n",
    "        if counter < 21 :\n",
    "            folder_name = \"B/Training\"\n",
    "        else :\n",
    "            folder_name = \"B/Testing\"\n",
    "\n",
    "        # Membuat folder jika belum ada\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "\n",
    "        # Mendapatkan nama file tanpa ekstensi\n",
    "        base_name = os.path.splitext(os.path.basename(image))[0]\n",
    "\n",
    "        # Membuat nama file untuk hasil\n",
    "        file_name = f\"result_{base_name}.png\"\n",
    "\n",
    "        # Path lengkap ke file yang akan disimpan\n",
    "        file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "        # Menyimpan gambar menggunakan OpenCV\n",
    "        cv2.imwrite(file_path, output_image_od)\n",
    "\n",
    "    else:\n",
    "        print(\"Kontur tidak cukup poin untuk fitting ellips.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Batas OD\n",
    "    input_img_rgb = cv2.imread(image)\n",
    "    actual_oc_gray = cv2.cvtColor(actual_oc, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the number of non-zero pixels full images\n",
    "    oc_pixel = cv2.countNonZero(actual_oc_gray)\n",
    "    cv2.rectangle(fundus_image, (x1+xa, y1+ya), (x2+xa, y2+ya), (0, 255, 0), 2)\n",
    "    cv2.rectangle(fundus_image_copy, (x1+xa, y1+ya), (x2+xa, y2+ya), (0, 255, 0), 2)\n",
    "\n",
    "    # Now perform the multiplication\n",
    "    segmented_optic_disk = cv2.bitwise_and(input_img_rgb, input_img_rgb, mask=optic_disc_filled_binary)\n",
    "    height, width, _ = fundus_image.shape\n",
    "    oc = segmented_optic_disk[ya+y1:y2+ya,x1+xa:x2+xa]\n",
    "\n",
    "    # Nama folder tempat gambar akan disimpan\n",
    "    if counter < 21 :\n",
    "        folder_name = \"A/Training\"\n",
    "    else :\n",
    "        folder_name = \"A/Testing\"\n",
    "\n",
    "    # Membuat folder jika belum ada\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "    # Mendapatkan nama file tanpa ekstensi\n",
    "    base_name = os.path.splitext(os.path.basename(image))[0]\n",
    "\n",
    "    # Membuat nama file untuk hasil\n",
    "    file_name = f\"result_{base_name}.png\"\n",
    "\n",
    "    # Path lengkap ke file yang akan disimpan\n",
    "    file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "    # Menyimpan gambar menggunakan OpenCV\n",
    "    cv2.imwrite(file_path, fundus_image_copy)\n",
    "\n",
    "\n",
    "    # # Pisahkan gambar menjadi tiga komponen warna\n",
    "    b, g, r = cv2.split(oc)\n",
    "\n",
    "    # # Konversi B, G, R dari format OpenCV (BGR) ke format yang bisa ditampilkan matplotlib (RGB)\n",
    "    # # Untuk itu, kita perlu mengatur R, G, B ke channel-nya masing-masing di gambar RGB.\n",
    "    zeros = np.zeros_like(b)  # array dengan nilai nol untuk channel lain\n",
    "    R_oc = cv2.merge([zeros, zeros, r])  # Hanya komponen merah\n",
    "    G_oc = cv2.merge([zeros, g, zeros])  # Hanya komponen hijau\n",
    "    B_oc = cv2.merge([b, zeros, zeros])  # Hanya komponen biru\n",
    "\n",
    "    # Hitung nilai minimum dan maksimum dari setiap saluran warna\n",
    "    min_r, max_r = np.min(r), np.max(r)\n",
    "\n",
    "    # Lakukan kontras stretching pada saluran merah\n",
    "    r_stretched = ((r - min_r) / (max_r - min_r)) * 255\n",
    "    r_stretched = np.uint8(r_stretched)\n",
    "\n",
    "    # Gabungkan kembali saluran warna merah yang telah dimodifikasi dengan saluran hijau dan biru yang kosong\n",
    "    stretched_img = cv2.merge((zeros, zeros, r_stretched))\n",
    "\n",
    "    # Stretched hist\n",
    "    hist_stretch = cv2.calcHist([r_stretched], [0], None, [256], [0, 256])\n",
    "    \n",
    "    # Pisahkan citra menjadi tiga kanal: B, G, R\n",
    "    b, g, r = cv2.split(stretched_img)\n",
    "\n",
    "    # Buat mask berdasarkan kondisi threshold pada kanal merah\n",
    "    mask = r < 210\n",
    "\n",
    "    # Set nilai pada mask menjadi 0 pada kanal merah\n",
    "    r[mask] = 0\n",
    "\n",
    "    zeros = np.zeros_like(r)\n",
    "    # Gabungkan kembali kanal B, G, R menjadi citra RGB\n",
    "    oc_if = cv2.merge([zeros, zeros, r])\n",
    "    oc_if_hist = cv2.calcHist([oc_if], [2], None, [256], [0, 256])\n",
    "\n",
    "    # Perform morphological closing\n",
    "    kernel_close = np.ones((30,30),np.uint8)\n",
    "    closed_oc = cv2.morphologyEx(oc_if, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "    # Convert closed_image to grayscale if it's not already in grayscale\n",
    "    if len(closed_oc.shape) > 2:\n",
    "        closed_oc_gray = cv2.cvtColor(closed_oc, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        closed_oc_gray = closed_oc\n",
    "\n",
    "    # Ensure the image is in the correct format (CV_8UC1)\n",
    "    closed_oc_uint8 = np.uint8(closed_oc_gray)\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(closed_oc_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Check if any contours were found\n",
    "    if not contours:\n",
    "        raise ValueError(\"No contours found in the image\")\n",
    "\n",
    "    # Get the largest contour\n",
    "    largest_contour_OC = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Fit ellipse ke kontur terbesar\n",
    "    if len(largest_contour_OC) >= 20:  # Minimum number of points required to fit ellipse\n",
    "        ellipse_OC = cv2.fitEllipse(largest_contour_OC)\n",
    "        # Ekstrak informasi pusat dan parameter ellips lainnya\n",
    "        (x_center, y_center), (major_axis, minor_axis), angle = ellipse_OC\n",
    "\n",
    "        # Hitung pusat baru dengan penambahan nilai translasi\n",
    "        new_x_center = x_center + x1 + xa\n",
    "        new_y_center = y_center + y1 + ya\n",
    "\n",
    "        # Bentuk ellips baru dengan pusat yang telah digeser\n",
    "        shifted_ellipse = ((new_x_center, new_y_center), (major_axis, minor_axis), angle)\n",
    "    \n",
    "        # Gambar ellips ke ROI\n",
    "        oc_with_ellipse_filling = cv2.ellipse(oc, ellipse_OC, (255, 255, 255), -1)\n",
    "\n",
    "        # Gambar ellips yang diperkirakan di atas citra RGB\n",
    "        input_ellipse_filling = cv2.ellipse(input_img_rgb, shifted_ellipse, (255, 255, 255), -1)\n",
    "        optic_cup_filled = cv2.ellipse(input_ellipse_filling, shifted_ellipse, (255, 255, 255), -1)\n",
    "        optic_cup_filled_gray =cv2.cvtColor(optic_cup_filled, cv2.COLOR_BGR2GRAY)\n",
    "        _, optic_cup_filled_binary = cv2.threshold(optic_cup_filled_gray, 254, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Menginisialisasi hitung untuk false negative, false positive, dan true positive\n",
    "        false_negative = 0\n",
    "        false_positive = 0\n",
    "        true_positive = 0\n",
    "        \n",
    "        #Hitung F-Score OC\n",
    "        #Looping untuk setiap piksel di kedua citra perhitungan F-Score\n",
    "        # for y in range(height):\n",
    "        #     for x in range(width):\n",
    "        #         # Mengecek false negative\n",
    "        #         if optic_cup_filled_binary[y, x] == 0 and actual_oc_gray[y, x] == 255:\n",
    "        #             false_negative += 1\n",
    "        #         # Mengecek false positive\n",
    "        #         elif optic_cup_filled_binary[y, x] == 255 and actual_oc_gray[y, x] == 0:\n",
    "        #             false_positive += 1\n",
    "        #         # Mengecek true positive\n",
    "        #         elif optic_cup_filled_binary[y, x] == 255 and actual_oc_gray[y, x] == 255:\n",
    "        #             true_positive += 1\n",
    "        # f_score_oc = true_positive*100/(true_positive+false_positive+false_negative)\n",
    "        # f_scores_oc.append(f_score_oc)\n",
    "        # print(f_score_oc)\n",
    "  \n",
    "        # # Tampilkan citra dengan ellips dan bounding box di ROI\n",
    "        # plt.imshow(cv2.cvtColor(input_ellipse_filling, cv2.COLOR_BGR2RGB))\n",
    "        # plt.title(\"Optic Disc \"+image)  # Ganti sesuai sumber gambar\n",
    "        # plt.axis('off')\n",
    "        # plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(\"Kontur tidak cukup poin untuk fitting ellips.\")\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerata %OD dan F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerata %OD yang didapatkan adalah 99.52%\n",
      "Rerata ROI Efficiency yang didapatkan adalah 39.79%\n",
      "Rerata F-Score yang didapatkan adalah 88.19%\n"
     ]
    }
   ],
   "source": [
    "# Average %OD\n",
    "avg_od = sum(od_percents)/len(od_percents)\n",
    "print(\"Rerata %OD yang didapatkan adalah {:.2f}%\".format(avg_od))\n",
    "\n",
    "# Average ROI Efficiency\n",
    "avg_roi = sum(roi_effs)/len(roi_effs)\n",
    "print(\"Rerata ROI Efficiency yang didapatkan adalah {:.2f}%\".format(avg_roi))\n",
    "\n",
    "# Average F-Score\n",
    "avg_f = sum(f_scores_od)/len(f_scores_od)\n",
    "print(\"Rerata F-Score yang didapatkan adalah {:.2f}%\".format(avg_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerata %OD yang didapatkan untuk data training adalah 99.55%\n",
      "Rerata ROI Efficiency yang didapatkan untuk data training adalah 40.58%\n",
      "Rerata F-Score yang didapatkan untuk data training adalah 88.97%\n"
     ]
    }
   ],
   "source": [
    "# Average %OD\n",
    "od_train = od_percents[:20]\n",
    "avg_od_train = sum(od_train) / len(od_train)\n",
    "print(\"Rerata %OD yang didapatkan untuk data training adalah {:.2f}%\".format(avg_od_train))\n",
    "\n",
    "# Average ROI Efficiency\n",
    "roi_train = roi_effs[:20]\n",
    "avg_roi_train = sum(roi_train) / len(roi_train)\n",
    "print(\"Rerata ROI Efficiency yang didapatkan untuk data training adalah {:.2f}%\".format(avg_roi_train))\n",
    "\n",
    "# Average F-Score\n",
    "f_scores_train = f_scores_od[:20]\n",
    "avg_f_train = sum(f_scores_train) / len(f_scores_train)\n",
    "print(\"Rerata F-Score yang didapatkan untuk data training adalah {:.2f}%\".format(avg_f_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerata %OD yang didapatkan untuk data testing adalah 98.71%\n",
      "Rerata ROI Efficiency yang didapatkan untuk data testing adalah 41.06%\n",
      "Rerata F-Score yang didapatkan untuk data testing adalah 86.71%\n"
     ]
    }
   ],
   "source": [
    "# Average %OD\n",
    "od_test = od_percents[-10:]\n",
    "avg_od_test = sum(od_test) / len(od_test)\n",
    "print(\"Rerata %OD yang didapatkan untuk data testing adalah {:.2f}%\".format(avg_od_test))\n",
    "\n",
    "# Average ROI Efficiency\n",
    "roi_test = roi_effs[-10:]\n",
    "avg_roi_test = sum(roi_test) / len(roi_test)\n",
    "print(\"Rerata ROI Efficiency yang didapatkan untuk data testing adalah {:.2f}%\".format(avg_roi_test))\n",
    "\n",
    "# Average F-Score\n",
    "f_scores_test = f_scores_od[-10:]\n",
    "avg_f_test = sum(f_scores_test) / len(f_scores_test)\n",
    "print(\"Rerata F-Score yang didapatkan untuk data testing adalah {:.2f}%\".format(avg_f_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[206], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Average F-Score\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m avg_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf_scores_od\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf_scores_oc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRerata F-Score yang didapatkan adalah \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(avg_f))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Average F-Score\u001b[39;00m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "# Average F-Score\n",
    "avg_f = sum(f_scores_od)/len(f_scores_oc)\n",
    "print(\"Rerata F-Score yang didapatkan adalah {:.2f}%\".format(avg_f))\n",
    "# Average F-Score\n",
    "f_scores_test = f_scores_oc[-10:]\n",
    "avg_f_test = sum(f_scores_test) / len(f_scores_test)\n",
    "print(\"Rerata F-Score yang didapatkan untuk data testing adalah {:.2f}%\".format(avg_f_test))\n",
    "# Average F-Score\n",
    "f_scores_train = f_scores_oc[:20]\n",
    "avg_f_train = sum(f_scores_train) / len(f_scores_train)\n",
    "print(\"Rerata F-Score yang didapatkan untuk data training adalah {:.2f}%\".format(avg_f_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%OD :\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mOD :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m od_percents :\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mitem\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mROI Efficiency :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m roi_effs :\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "print(\"%OD :\")\n",
    "for item in od_percents :\n",
    "    print(item+\", \")\n",
    "\n",
    "print(\"ROI Efficiency :\")\n",
    "for item in roi_effs :\n",
    "    print(item+\", \")\n",
    "\n",
    "print(\"F-Score\")\n",
    "for item in f_scores :\n",
    "    print(item+\", \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
