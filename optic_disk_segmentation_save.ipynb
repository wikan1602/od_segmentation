{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling All Autobots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import exposure\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for histogram matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for histogram matching\n",
    "def histogram_matching(source, template):\n",
    "    matched = exposure.match_histograms(source, template, channel_axis=None)\n",
    "    return matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data training\n",
    "image1 = 'Images/training/drishtiGS_017.png'\n",
    "image2 = 'Images/training/drishtiGS_032.png'\n",
    "image3 = 'Images/training/drishtiGS_036.png'\n",
    "image4 = 'Images/training/drishtiGS_037.png'\n",
    "image5 ='Images/training/drishtiGS_040.png'\n",
    "image6 = 'Images/training/drishtiGS_042.png'\n",
    "image7 = 'Images/training/drishtiGS_049.png'\n",
    "image8 = 'Images/training/drishtiGS_057.png'\n",
    "image9 = 'Images/training/drishtiGS_060.png'\n",
    "image10 = 'Images/training/drishtiGS_063.png'\n",
    "image11 = 'Images/training/drishtiGS_064.png'\n",
    "image12 = 'Images/training/drishtiGS_066.png'\n",
    "image13 = 'Images/training/drishtiGS_068.png'\n",
    "image14 = 'Images/training/drishtiGS_069.png'\n",
    "image15 = 'Images/training/drishtiGS_080.png'\n",
    "image16 = 'Images/training/drishtiGS_081.png'\n",
    "image17 = 'Images/training/drishtiGS_084.png'\n",
    "image18 = 'Images/training/drishtiGS_088.png'\n",
    "image19 = 'Images/training/drishtiGS_094.png'\n",
    "image20 = 'Images/training/drishtiGS_098.png'\n",
    "\n",
    "#Data Testing\n",
    "image21 = 'Images/testing/drishtiGS_033.png'\n",
    "image22 = 'Images/testing/drishtiGS_038.png'\n",
    "image23 = 'Images/testing/drishtiGS_041.png'\n",
    "image24 = 'Images/testing/drishtiGS_046.png'\n",
    "image25 = 'Images/testing/drishtiGS_051.png'\n",
    "image26 = 'Images/testing/drishtiGS_058.png'\n",
    "image27 = 'Images/testing/drishtiGS_076.png'\n",
    "image28 = 'Images/testing/drishtiGS_089.png'\n",
    "image29 = 'Images/testing/drishtiGS_090.png'\n",
    "image30 = 'Images/testing/drishtiGS_092.png'\n",
    "\n",
    "\n",
    "# Buat list yang berisi semua variabel gambar\n",
    "images = [\n",
    "    image1, image2, image3, image4, image5,\n",
    "    image6, image7, image8, image9, image10,\n",
    "    image11, image12, image13, image14, image15,\n",
    "    image16, \n",
    "    image17, image18, \n",
    "    image19, image20,\n",
    "    image21, image22, image23, image24, image25,\n",
    "    image26, image27, image28, image29, image30\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OD Actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data training\n",
    "actual1 = 'Images/OD_training/drishtiGS_017_ODAvgBoundary_OD_img.png'\n",
    "actual2 = 'Images/OD_training/drishtiGS_032_ODAvgBoundary_OD_img.png'\n",
    "actual3 = 'Images/OD_training/drishtiGS_036_ODAvgBoundary_OD_img.png'\n",
    "actual4 = 'Images/OD_training/drishtiGS_037_ODAvgBoundary_OD_img.png'\n",
    "actual5 ='Images/OD_training/drishtiGS_040_ODAvgBoundary_OD_img.png'\n",
    "actual6 = 'Images/OD_training/drishtiGS_042_ODAvgBoundary_OD_img.png'\n",
    "actual7 = 'Images/OD_training/drishtiGS_049_ODAvgBoundary_OD_img.png'\n",
    "actual8 = 'Images/OD_training/drishtiGS_057_ODAvgBoundary_OD_img.png'\n",
    "actual9 = 'Images/OD_training/drishtiGS_060_ODAvgBoundary_OD_img.png'\n",
    "actual10 = 'Images/OD_training/drishtiGS_063_ODAvgBoundary_OD_img.png'\n",
    "actual11 = 'Images/OD_training/drishtiGS_064_ODAvgBoundary_OD_img.png'\n",
    "actual12 = 'Images/OD_training/drishtiGS_066_ODAvgBoundary_OD_img.png'\n",
    "actual13 = 'Images/OD_training/drishtiGS_068_ODAvgBoundary_OD_img.png'\n",
    "actual14 = 'Images/OD_training/drishtiGS_069_ODAvgBoundary_OD_img.png'\n",
    "actual15 = 'Images/OD_training/drishtiGS_080_ODAvgBoundary_OD_img.png'\n",
    "actual16 = 'Images/OD_training/drishtiGS_081_ODAvgBoundary_OD_img.png'\n",
    "actual17 = 'Images/OD_training/drishtiGS_084_ODAvgBoundary_OD_img.png'\n",
    "actual18 = 'Images/OD_training/drishtiGS_088_ODAvgBoundary_OD_img.png'\n",
    "actual19 = 'Images/OD_training/drishtiGS_094_ODAvgBoundary_OD_img.png'\n",
    "actual20 = 'Images/OD_training/drishtiGS_098_ODAvgBoundary_OD_img.png'\n",
    "\n",
    "#Data Testing\n",
    "actual21 = 'Images/OD_testing/drishtiGS_033_ODAvgBoundary_OD_img.png'\n",
    "actual22 = 'Images/OD_testing/drishtiGS_038_ODAvgBoundary_OD_img.png'\n",
    "actual23 = 'Images/OD_testing/drishtiGS_041_ODAvgBoundary_OD_img.png'\n",
    "actual24 = 'Images/OD_testing/drishtiGS_046_ODAvgBoundary_OD_img.png'\n",
    "actual25 = 'Images/OD_testing/drishtiGS_051_ODAvgBoundary_OD_img.png'\n",
    "actual26 = 'Images/OD_testing/drishtiGS_058_ODAvgBoundary_OD_img.png'\n",
    "actual27 = 'Images/OD_testing/drishtiGS_076_ODAvgBoundary_OD_img.png'\n",
    "actual28 = 'Images/OD_testing/drishtiGS_089_ODAvgBoundary_OD_img.png'\n",
    "actual29 = 'Images/OD_testing/drishtiGS_090_ODAvgBoundary_OD_img.png'\n",
    "actual30 = 'Images/OD_testing/drishtiGS_092_ODAvgBoundary_OD_img.png'\n",
    "\n",
    "# Buat list yang berisi semua variabel gambar\n",
    "actuals = [\n",
    "    actual1, actual2, actual3, actual4, actual5,\n",
    "    actual6, actual7, actual8, actual9, actual10,\n",
    "    actual11, actual12, actual13, actual14, actual15,\n",
    "    actual16, actual17, actual18, actual19, actual20, \n",
    "    actual21, actual22, actual23, actual24, actual25,\n",
    "    actual26, actual27, actual28, actual29, actual30\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read reference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reference image and input image\n",
    "reference_image_path = 'Images/training/drishtiGS_037.png'\n",
    "# Load the images\n",
    "reference_image = cv2.imread(reference_image_path)\n",
    "# Convert images to grayscale\n",
    "gray_reference = cv2.cvtColor(reference_image, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List to save %OD, F-Score, ROI Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "od_percents = []\n",
    "f_scores = []\n",
    "roi_effs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pixel limit for initial cropping & Counter for saving location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa = 100\n",
    "xb = 100\n",
    "ya = 550\n",
    "yb = 1300\n",
    "counter = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iteration 20 Images to get OD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, actual in zip(images, actuals):\n",
    "    fundus_image = cv2.imread(image)\n",
    "    fundus_image_copy = fundus_image.copy()\n",
    "    actual_od = cv2.imread(actual)\n",
    "\n",
    "    gray_image = cv2.cvtColor(fundus_image, cv2.COLOR_BGR2GRAY)\n",
    "    # Perform histogram matching\n",
    "    matched_image = histogram_matching(gray_image, gray_reference)\n",
    "    # Get the dimensions of the image\n",
    "    height, width, _ = fundus_image.shape\n",
    "\n",
    "    # Crop the image along the y-axis from 550 to 1300\n",
    "    # Taking the entire width for x-axis\n",
    "    fundus_cropped = matched_image[ya:yb, xa:width-xb] #gray\n",
    "    RGB_cropped = fundus_image[ya:yb, xa:width-xb]\n",
    "\n",
    "    # Apply thresholding\n",
    "    _, binary_image = cv2.threshold(fundus_cropped, 100, 255, cv2.THRESH_BINARY)\n",
    "    # Perform morphological opening\n",
    "    kernel_open = np.ones((20, 20), np.uint8)\n",
    "    opened_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel_open)\n",
    "    # Perform morphological closing\n",
    "    kernel_close = np.ones((100, 100), np.uint8)\n",
    "    closed_image = cv2.morphologyEx(opened_image, cv2.MORPH_CLOSE, kernel_close)\n",
    "    \n",
    "    # Convert closed_image to grayscale if it's not already in grayscale\n",
    "    if len(closed_image.shape) > 2:\n",
    "        closed_image_gray = cv2.cvtColor(closed_image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        closed_image_gray = closed_image\n",
    "\n",
    "    # Ensure the image is in the correct format (CV_8UC1)\n",
    "    closed_image_uint8 = np.uint8(closed_image_gray)\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(closed_image_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Check if any contours were found\n",
    "    if not contours:\n",
    "        raise ValueError(\"No contours found in the image\")\n",
    "\n",
    "    # Get the largest contour\n",
    "    largest_contour_ROI = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    #Initialize x1,x2,y1,y2 to become global variables\n",
    "    x1=0\n",
    "    x2=0\n",
    "    y1=0\n",
    "    y2=0\n",
    "\n",
    "    # Fit ellipse ke kontur terbesar\n",
    "    if len(largest_contour_ROI) >= 5:  # Minimum number of points required to fit ellipse\n",
    "        ellipse_ROI = cv2.fitEllipse(largest_contour_ROI)\n",
    "        \n",
    "        # Get the parameters of the ellipse\n",
    "        (center, axes, angle) = ellipse_ROI\n",
    "        center_x, center_y = center\n",
    "        width, height = axes\n",
    "\n",
    "        # Calculate bounding box of the ellipse\n",
    "        x1 = int(center_x - width // 2)-100\n",
    "        x2 = int(center_x + width // 2)+100\n",
    "        y1 = int(center_y - height // 2)-100\n",
    "        y2 = int(center_y + height // 2)+100\n",
    "\n",
    "        # Ensure the crop area is within the image bounds\n",
    "        y1, y2 = max(0, y1), min(fundus_cropped.shape[0], y2)\n",
    "        x1, x2 = max(0, x1), min(fundus_cropped.shape[1], x2)\n",
    "\n",
    "        # Crop the image to the bounding box of the ellipse\n",
    "        roi_cropped = fundus_cropped[y1:y2, x1:x2]\n",
    "        roi_rgb = RGB_cropped[y1:y2, x1:x2]\n",
    "\n",
    "        # Convert RGB_cropped to RGB format\n",
    "        color_image = cv2.cvtColor(RGB_cropped, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Draw ellipse on the color image\n",
    "        cv2.ellipse(color_image, ellipse_ROI, (0, 0, 255), 2)\n",
    "\n",
    "    else:\n",
    "        print(\"There are not enough contour points for elliptical fitting.\")\n",
    "    \n",
    "    # Convert actual_od to a single-channel image if necessary\n",
    "    actual_od_gray = cv2.cvtColor(actual_od, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate the number of non-zero pixels full images\n",
    "    od_pixel = cv2.countNonZero(actual_od_gray)\n",
    "\n",
    "    # Get the dimensions of the image\n",
    "    height, width, _ = actual_od.shape\n",
    "\n",
    "    # Crop the image along the y-axis from 700 to 1400\n",
    "    # Taking the entire width for x-axis\n",
    "    actual_od_crop = actual_od_gray[ya:yb, xa:width-xb]\n",
    "\n",
    "    # Cropping sesuai ROI\n",
    "    actual_od_roi = actual_od_crop[y1:y2, x1:x2]\n",
    "\n",
    "    # Calculate the total number of pixels in the ROI\n",
    "    total_pixel_roi = cv2.countNonZero(actual_od_roi)\n",
    "\n",
    "    # Calculate the percentage of ROI obtained in the image\n",
    "    od_percent = (total_pixel_roi/od_pixel) * 100\n",
    "    od_percents.append(od_percent)\n",
    "\n",
    "    # Get the shape of actual_od_roi\n",
    "    height_roi, width_roi = actual_od_roi.shape\n",
    "    \n",
    "    # Calculate the ROI Efficiency\n",
    "    roi_eff = total_pixel_roi*100 / (height_roi * width_roi)\n",
    "    roi_effs.append(roi_eff)\n",
    "\n",
    "    # Split channel\n",
    "    B, G, R = cv2.split(roi_rgb)\n",
    "    \n",
    "    # Convert B, G, R from OpenCV format (BGR) to matplotlib displayable format (RGB)\n",
    "    # # For that, we need to set R, G, B to their respective channels in the RGB image.\n",
    "    zeros = np.zeros_like(B)  # array dengan nilai nol untuk channel lain\n",
    "    R_img = cv2.merge([zeros, zeros, R])  # Red Only\n",
    "    G_img = cv2.merge([zeros, G, zeros])  # Green Only\n",
    "    B_img = cv2.merge([B, zeros, zeros])  # Blue Only\n",
    "\n",
    "    # Calculate the histogram for each channel (B, G, R)\n",
    "    hist_b = cv2.calcHist([roi_rgb], [0], None, [256], [0, 256])\n",
    "    hist_g = cv2.calcHist([roi_rgb], [1], None, [256], [0, 256])\n",
    "    hist_r = cv2.calcHist([roi_rgb], [2], None, [256], [0, 256])\n",
    "\n",
    "    # Hitung nilai minimum dan maksimum dari setiap saluran warna\n",
    "    min_r, max_r = np.min(R), np.max(R)\n",
    "\n",
    "    # Perform contrast stretching on the red channel\n",
    "    r_stretched = ((R - min_r) / (max_r - min_r)) * 255\n",
    "    r_stretched = np.uint8(r_stretched)\n",
    "\n",
    "    # Recombine the modified red color channel with the empty green and blue channels\n",
    "    stretched_img = cv2.merge((zeros, zeros, r_stretched))\n",
    "\n",
    "    # Stretched hist\n",
    "    hist_stretch = cv2.calcHist([r_stretched], [0], None, [256], [0, 256])\n",
    "    \n",
    "    # split channel\n",
    "    b, g, r = cv2.split(stretched_img)\n",
    "\n",
    "    # Create a mask based on the threshold condition in the red channel\n",
    "    mask = r < 150\n",
    "\n",
    "    # Set the value of the mask to 0 in the red channel\n",
    "    r[mask] = 0\n",
    "\n",
    "    # Rejoin channels\n",
    "    pass_if_img = cv2.merge([b, g, r])\n",
    "    pass_if_img_r = cv2.calcHist([pass_if_img], [2], None, [256], [0, 256])\n",
    "\n",
    "    # Perform morphological closing\n",
    "    kernel_close = np.ones((30,30),np.uint8)\n",
    "    closed_image = cv2.morphologyEx(pass_if_img, cv2.MORPH_CLOSE, kernel_close)\n",
    "\n",
    "    # Convert closed_image to grayscale if it's not already in grayscale\n",
    "    if len(closed_image.shape) > 2:\n",
    "        closed_image_gray = cv2.cvtColor(closed_image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        closed_image_gray = closed_image\n",
    "\n",
    "    # Ensure the image is in the correct format (CV_8UC1)\n",
    "    closed_image_uint8 = np.uint8(closed_image_gray)\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(closed_image_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Check if any contours were found\n",
    "    if not contours:\n",
    "        raise ValueError(\"No contours found in the image\")\n",
    "\n",
    "    # Get the largest contour\n",
    "    largest_contour_OD = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    # Fit the ellipse to the largest contour\n",
    "    if len(largest_contour_OD) >= 20:  # Minimum number of points required to fit ellipse\n",
    "        ellipse_OD = cv2.fitEllipse(largest_contour_OD)\n",
    "        # Extract center information and other ellipse parameters\n",
    "        (x_center, y_center), (major_axis, minor_axis), angle = ellipse_OD\n",
    "\n",
    "        # Calculate the new center with the addition of the translation value\n",
    "        new_x_center = x_center + x1 + xa # added according to the earliest cropping\n",
    "        new_y_center = y_center + y1 + ya # added according to the earliest cropping\n",
    "\n",
    "        # New ellipse shape with shifted center\n",
    "        shifted_ellipse = ((new_x_center, new_y_center), (major_axis, minor_axis), angle)\n",
    "\n",
    "        # Gambar ellips yang diperkirakan di atas citra RGB\n",
    "        optic_disc_with_ellipse = cv2.ellipse(fundus_image, shifted_ellipse, (0, 255, 0), 2)     \n",
    "        optic_disc_filled = cv2.ellipse(fundus_image, shifted_ellipse, (255, 255, 255), -1)\n",
    "        optic_disc_filled_gray =cv2.cvtColor(optic_disc_filled, cv2.COLOR_BGR2GRAY)\n",
    "        _, optic_disc_filled_binary = cv2.threshold(optic_disc_filled_gray, 254, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # bounding box\n",
    "        cv2.rectangle(fundus_image_copy, (x1+xa, y1+ya), (x2+xa, y2+ya), (0, 255, 0), 2)\n",
    "        \n",
    "        # false negative, false positive, dan true positive\n",
    "        false_negative = 0\n",
    "        false_positive = 0\n",
    "        true_positive = 0\n",
    "\n",
    "        output_image_od = cv2.cvtColor(optic_disc_filled_binary, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        # Looping untuk setiap piksel di kedua citra perhitungan F-Score\n",
    "        for y in range(height):\n",
    "            for x in range(width):\n",
    "                # false negative\n",
    "                if optic_disc_filled_binary[y, x] == 0 and actual_od_gray[y, x] == 255:\n",
    "                    false_negative += 1\n",
    "                    output_image_od[y, x] = [0, 0, 255]  # Red\n",
    "                # false positive\n",
    "                elif optic_disc_filled_binary[y, x] == 255 and actual_od_gray[y, x] == 0:\n",
    "                    false_positive += 1\n",
    "                    output_image_od[y, x] = [0, 255, 255]  # Yellow\n",
    "                # true positive\n",
    "                elif optic_disc_filled_binary[y, x] == 255 and actual_od_gray[y, x] == 255:\n",
    "                    true_positive += 1\n",
    "                    output_image_od[y, x] = [0, 255, 0]  # Green\n",
    "        f_score_od = true_positive*100/(true_positive+false_positive+false_negative)\n",
    "        f_scores.append(f_score_od)\n",
    "\n",
    "        segmented_optic_disk = cv2.bitwise_and(fundus_image_copy, fundus_image_copy, mask=optic_disc_filled_binary)\n",
    "\n",
    "        # Saving\n",
    "        if counter < 21 :\n",
    "            folder_A = \"A/Training\"\n",
    "            folder_B = \"B/Training\"\n",
    "            folder_OD = \"Result OD/Training\"\n",
    "        else :\n",
    "            folder_A = \"A/Testing\"\n",
    "            folder_B = \"B/Testing\"\n",
    "            folder_OD = \"Result OD/Testing\"\n",
    "\n",
    "        # Create a folder if it doesn't exist yet\n",
    "        if not os.path.exists(folder_A):\n",
    "            os.makedirs(folder_A)\n",
    "        if not os.path.exists(folder_B):\n",
    "            os.makedirs(folder_B)\n",
    "        if not os.path.exists(folder_OD):\n",
    "            os.makedirs(folder_OD)\n",
    "\n",
    "        # Gets the file name without extension\n",
    "        base_name = os.path.splitext(os.path.basename(image))[0]\n",
    "\n",
    "        # Create a file name for the results\n",
    "        file_A = f\"{base_name}_A.png\"\n",
    "        file__B = f\"{base_name}_B.png\"\n",
    "        file_OD = f\"{base_name}_Result OD.png\"\n",
    "        \n",
    "        # Path lengkap ke file yang akan disimpan\n",
    "        file_path_A = os.path.join(folder_A, file_A)\n",
    "        file_path_B = os.path.join(folder_B, file__B)\n",
    "        file_path_OD = os.path.join(folder_OD, file_OD)\n",
    "\n",
    "        # Menyimpan gambar menggunakan OpenCV\n",
    "        cv2.imwrite(file_path_A, fundus_image_copy)     \n",
    "        cv2.imwrite(file_path_B, output_image_od)     \n",
    "        cv2.imwrite(file_path_OD, segmented_optic_disk)\n",
    "    else:\n",
    "        print(\"There are not enough contour points for elliptical fitting\")\n",
    "    counter = counter + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rerata %OD dan F-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average %OD obtained is 99.55%\n",
      "The average ROI Efficiency obtained is 39.60%\n",
      "The average F-Score obtained is 88.03%\n"
     ]
    }
   ],
   "source": [
    "# Average %OD\n",
    "avg_od = sum(od_percents)/len(od_percents)\n",
    "print(\"The average %OD obtained is {:.2f}%\".format(avg_od))\n",
    "\n",
    "# Average ROI Efficiency\n",
    "avg_roi = sum(roi_effs)/len(roi_effs)\n",
    "print(\"The average ROI Efficiency obtained is {:.2f}%\".format(avg_roi))\n",
    "\n",
    "# Average F-Score\n",
    "avg_f = sum(f_scores)/len(f_scores)\n",
    "print(\"The average F-Score obtained is {:.2f}%\".format(avg_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average %OD obtained for training data is 99.98%\n",
      "The average ROI Efficiency obtained for training data is 38.87%\n",
      "The average F-Score obtained for training data is 88.69%\n"
     ]
    }
   ],
   "source": [
    "# Average %OD\n",
    "od_train = od_percents[:20]\n",
    "avg_od_train = sum(od_train) / len(od_train)\n",
    "print(\"The average %OD obtained for training data is {:.2f}%\".format(avg_od_train))\n",
    "\n",
    "# Average ROI Efficiency\n",
    "roi_train = roi_effs[:20]\n",
    "avg_roi_train = sum(roi_train) / len(roi_train)\n",
    "print(\"The average ROI Efficiency obtained for training data is {:.2f}%\".format(avg_roi_train))\n",
    "\n",
    "# Average F-Score\n",
    "f_scores_train = f_scores[:20]\n",
    "avg_f_train = sum(f_scores_train) / len(f_scores_train)\n",
    "print(\"The average F-Score obtained for training data is {:.2f}%\".format(avg_f_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average %OD obtained for testing data is 98.71%\n",
      "The average ROI Efficiency obtained for testing data is 41.06%\n",
      "The average F-Score obtained for testing data is 86.71%\n"
     ]
    }
   ],
   "source": [
    "# Average %OD\n",
    "od_test = od_percents[-10:]\n",
    "avg_od_test = sum(od_test) / len(od_test)\n",
    "print(\"The average %OD obtained for testing data is {:.2f}%\".format(avg_od_test))\n",
    "\n",
    "# Average ROI Efficiency\n",
    "roi_test = roi_effs[-10:]\n",
    "avg_roi_test = sum(roi_test) / len(roi_test)\n",
    "print(\"The average ROI Efficiency obtained for testing data is {:.2f}%\".format(avg_roi_test))\n",
    "\n",
    "# Average F-Score\n",
    "f_scores_test = f_scores[-10:]\n",
    "avg_f_test = sum(f_scores_test) / len(f_scores_test)\n",
    "print(\"The average F-Score obtained for testing data is {:.2f}%\".format(avg_f_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
